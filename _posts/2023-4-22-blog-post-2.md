---
title: 'The Reading of ManiTrans: Entity-Level Text-Guided Image Manipulation via Token-wise Semantic Alignment and Generation '
date: 2023-04-22
permalink: /posts/2023/04/blog-post-2/
tags:
  - Image
  - Generation
  - Reading
---

## Overall framwork
This paper presents a Transformer-based framework called *ManiTrans* to address the entity-Level Text-Guided Image Manipulation (eL-TGIM) problem.

![Overall framwork](/images/2023/04/post2/pic0.png)

The Transformer-based image processing model in this framework includes an AutoEncoder (used to sample and quantize the input image into discrete tokens), a Transformer (used to fit the joint distribution of image tokens), and a Decoder (used for image reconstruction).

To locate the image tokens determined by the input text that need to be manipulated, a semantic alignment module is designed. This module consists of two parts: Entity Segmentation, which segments the image to find the tokens corresponding to each entity, and Semantic Alignment, which selects the tokens corresponding to the prompt. Both parts are composed of existing models.

## Innovations
* A Transformer-based entity-level text-guided image processing framework is proposed that can manipulate not only the texture/color of individual objects but also the structure of objects and manipulate multiple objects.
* A semantic alignment module is proposed to locate image markers related to text for flexible manipulation. Semantic loss is used to achieve better visual-semantic alignment and concrete training signals.

## Experimental Design
Mainly compared ManiTrans with ManGAN and Lightweight-GAN and conducted tests on the CUB, Oxford, and COCO public datasets. The main evaluation indicators include: IS, CLIP-core, R@10, and L2-error.

**Qualitative experiment**: Conducted experiments with and without visual guidance. Observe whether the generated images meet the requirements of the input text.

**Quantitative experiment**: Examined the performance of different models on the dataset.

**Comparison with the State of the Art**: Mainly compared the difference between with and without semantic loss and the impact of Word-patch Alignment and Semantic Alignment on the results.